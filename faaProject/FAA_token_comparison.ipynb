{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b93ae8-841f-4d69-b64b-b26b3e648e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this notebook compares the word tokenization of 'c119' and 'remark'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "import nltk\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ae9a25-3067-45b3-af94-fe0aa93958f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"c78\", \"c119\",\"remark\"]\n",
    "labels = ['AU', 'ME', 'AF', 'DE', 'II', 'EQ', 'AI']\n",
    "Corpus = pd.read_csv(\"./Subsets/Maintenance_Text_data.csv\",encoding='latin-1', header=0, usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e01a3c-50fe-4301-9379-c231485c04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_name = 'remark'\n",
    "\n",
    "# Step - a : Remove blank rows if any.\n",
    "Corpus[row_name].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "Corpus[row_name] = [str(entry).lower() for entry in Corpus[row_name]]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "Corpus[row_name]= [word_tokenize(entry) for entry in Corpus[row_name]]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index,entry in enumerate(Corpus[row_name]):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final_remark'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dfba494-375e-4d67-a1df-c41eaea62c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c119</th>\n",
       "      <th>c78</th>\n",
       "      <th>remark</th>\n",
       "      <th>text_final_remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAILWHEEL COCKED RIGHT PRIOR TO takeoff</td>\n",
       "      <td>AU</td>\n",
       "      <td>[tailwheel, cocked, right, prior, to, takeoff]</td>\n",
       "      <td>['tailwheel', 'cock', 'right', 'prior', 'takeo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOW PLANE BECAME AIRBORNE THEN SETTLED STUDENT...</td>\n",
       "      <td>ME</td>\n",
       "      <td>[tow, plane, became, airborne, then, settled, ...</td>\n",
       "      <td>['tow', 'plane', 'become', 'airborne', 'settle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ND ILS APCH,aircraft'S G/S INOP LOM TUNED TO ...</td>\n",
       "      <td>AU</td>\n",
       "      <td>[2nd, ils, apch, ,, aircraft, 's, g/s, inop, l...</td>\n",
       "      <td>['il', 'apch', 'aircraft', 'inop', 'lom', 'tun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pilot NOTED SOFT right BRAKE PEDAL DRG TAXI TO...</td>\n",
       "      <td>AU</td>\n",
       "      <td>[pilot, noted, soft, right, brake, pedal, drg,...</td>\n",
       "      <td>['pilot', 'note', 'soft', 'right', 'brake', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAXI OFF HARD SFC DUE TFC right MAIN GR BROKE ...</td>\n",
       "      <td>AF</td>\n",
       "      <td>[taxi, off, hard, sfc, due, tfc, right, main, ...</td>\n",
       "      <td>['taxi', 'hard', 'sfc', 'due', 'tfc', 'right',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                c119 c78  \\\n",
       "0           TAILWHEEL COCKED RIGHT PRIOR TO takeoff   AU   \n",
       "1  TOW PLANE BECAME AIRBORNE THEN SETTLED STUDENT...  ME   \n",
       "2  2ND ILS APCH,aircraft'S G/S INOP LOM TUNED TO ...  AU   \n",
       "3  pilot NOTED SOFT right BRAKE PEDAL DRG TAXI TO...  AU   \n",
       "4  TAXI OFF HARD SFC DUE TFC right MAIN GR BROKE ...  AF   \n",
       "\n",
       "                                              remark  \\\n",
       "0     [tailwheel, cocked, right, prior, to, takeoff]   \n",
       "1  [tow, plane, became, airborne, then, settled, ...   \n",
       "2  [2nd, ils, apch, ,, aircraft, 's, g/s, inop, l...   \n",
       "3  [pilot, noted, soft, right, brake, pedal, drg,...   \n",
       "4  [taxi, off, hard, sfc, due, tfc, right, main, ...   \n",
       "\n",
       "                                   text_final_remark  \n",
       "0  ['tailwheel', 'cock', 'right', 'prior', 'takeo...  \n",
       "1  ['tow', 'plane', 'become', 'airborne', 'settle...  \n",
       "2  ['il', 'apch', 'aircraft', 'inop', 'lom', 'tun...  \n",
       "3  ['pilot', 'note', 'soft', 'right', 'brake', 'p...  \n",
       "4  ['taxi', 'hard', 'sfc', 'due', 'tfc', 'right',...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = Corpus\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0646fc0-757c-4006-8d72-997d48f4fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"c78\", \"c119\",\"remark\"]\n",
    "labels = ['AU', 'ME', 'AF', 'DE', 'II', 'EQ', 'AI']\n",
    "Corpus = pd.read_csv(\"./Subsets/Maintenance_Text_data.csv\",encoding='latin-1', header=0, usecols=columns)\n",
    "row_name = 'c119'\n",
    "\n",
    "# Step - a : Remove blank rows if any.\n",
    "Corpus[row_name].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "Corpus[row_name] = [str(entry).lower() for entry in Corpus[row_name]]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "Corpus[row_name]= [word_tokenize(entry) for entry in Corpus[row_name]]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index,entry in enumerate(Corpus[row_name]):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final_c119'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3f700f-439a-46d9-9029-b3acde7d13a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Corpus['text_final_c119'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f1bbcc2-292d-4e28-9398-f523f05d5de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_df['text_final_remark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f9b2725-bf85-42a4-905b-7ef8b379f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = Corpus['text_final_c119'].compare(new_df['text_final_remark'], keep_shape=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "800b89a9-00c3-43b6-a01f-248137007a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_codes = list(new.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b167a13-0253-4044-ad40-e580fd506344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "II    535\n",
       "AU    103\n",
       "ME     48\n",
       "AF     35\n",
       "DE     23\n",
       "AI     11\n",
       "EQ      1\n",
       "Name: c78, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = pd.read_csv(\"./Subsets/Maintenance_Text_data.csv\",encoding='latin-1', header=0, usecols=columns)\n",
    "Corpus['c78'].iloc[lookup_codes].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810c797-8775-428f-87cf-59ef32bb8cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
